{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data/eval_diff.xlsxを読み込んで、dictに変換する\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def read_eval_diff(path='../data/eval_diff.csv'):\n",
    "    df = pd.read_csv(path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'【スマホでpolice brutalityを潰そう】mixidea高校定期練習': [3, 2, 2], '【小石川高校 vs WSDC連合】高校定期練【高校生のバイトって実際どうなん】': [3, 4, 2], '銀杏杯 2016 Oct. Gov.NitA Opp.KDS': [3, 3], '【民営化 vs 国営化】mixidea高校定期練習': [2, 3, 3], '【政治家の私生活報道】mixidea定期高校練習': [4, 2], '【確かに戦隊モノって女性ヒーローいないよに】mixidea高校定期練習': [2, 1], '【デュエルしようぜ】mixidea高校定期練習': [3, 2]}\n",
      "{'【スマホでpolice brutalityを潰そう】mixidea高校定期練習': 0.4714045207910317, '【小石川高校 vs WSDC連合】高校定期練【高校生のバイトって実際どうなん】': 0.816496580927726, '銀杏杯 2016 Oct. Gov.NitA Opp.KDS': 0.0, '【民営化 vs 国営化】mixidea高校定期練習': 0.4714045207910317, '【政治家の私生活報道】mixidea定期高校練習': 1.0, '【確かに戦隊モノって女性ヒーローいないよに】mixidea高校定期練習': 0.5, '【デュエルしようぜ】mixidea高校定期練習': 0.5}\n",
      "0.5370436603585413\n"
     ]
    }
   ],
   "source": [
    "data = read_eval_diff()\n",
    "\n",
    "dict_eval = {}\n",
    "for title in data[\"評価した動画タイトル\"]:\n",
    "    dict_eval[title] = []\n",
    "\n",
    "for title, eval in zip(data[\"評価した動画タイトル\"], data[\"試合全体に関して、各項目を評価してください。 [議論は噛み合っていましたか？]\"]):\n",
    "    if eval == \"そう思う\":\n",
    "        dict_eval[title].append(4)\n",
    "    elif eval == \"どちらかというとそう思う\":\n",
    "        dict_eval[title].append(3)\n",
    "    elif eval == \"どちらかというとそう思わない\":\n",
    "        dict_eval[title].append(2)\n",
    "    elif eval == \"そう思わない\":\n",
    "        dict_eval[title].append(1)\n",
    "\n",
    "#dict_evalから要素が一つだけなのを削除\n",
    "filter_dict_eval = {k: v for k, v in dict_eval.items() if len(v) > 1}\n",
    "\n",
    "print(filter_dict_eval)\n",
    "\n",
    "#それぞれに対し標準偏差を計算\n",
    "std_dict = {}\n",
    "for title, eval in filter_dict_eval.items():\n",
    "    std_dict\n",
    "    std_dict[title] = np.std(eval)\n",
    "\n",
    "print(std_dict)\n",
    "print(\"噛み合い度合い：\"+np.mean(list(std_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_eval_diff()\n",
    "\n",
    "dict_eval = {}\n",
    "for title in data[\"評価した動画タイトル\"]:\n",
    "    dict_eval[title] = []\n",
    "\n",
    "for title, eval in zip(data[\"評価した動画タイトル\"], data[\"試合全体に関して、各項目を評価してください。 [議論は噛み合っていましたか？]\"]):\n",
    "    if eval == \"そう思う\":\n",
    "        dict_eval[title].append(4)\n",
    "    elif eval == \"どちらかというとそう思う\":\n",
    "        dict_eval[title].append(3)\n",
    "    elif eval == \"どちらかというとそう思わない\":\n",
    "        dict_eval[title].append(2)\n",
    "    elif eval == \"そう思わない\":\n",
    "        dict_eval[title].append(1)\n",
    "\n",
    "#dict_evalから要素が一つだけなのを削除\n",
    "filter_dict_eval = {k: v for k, v in dict_eval.items() if len(v) > 1}\n",
    "\n",
    "print(filter_dict_eval)\n",
    "\n",
    "#それぞれに対し標準偏差を計算\n",
    "std_dict = {}\n",
    "for title, eval in filter_dict_eval.items():\n",
    "    std_dict\n",
    "    std_dict[title] = np.std(eval)\n",
    "\n",
    "print(std_dict)\n",
    "print(\"噛み合い度合い：\"+np.mean(list(std_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'丹羽\\u3000典子': 0.7399324293474372, '小林優稀': 0.6388765649999398}\n",
      "噛み合い度合い：0.6894044971736886\n"
     ]
    }
   ],
   "source": [
    "data = read_eval_diff()\n",
    "\n",
    "dict_eval = {}\n",
    "for name in data[\"氏名\"]:\n",
    "    dict_eval[name] = []\n",
    "\n",
    "for name, eval in zip(data[\"氏名\"], data[\"試合全体に関して、各項目を評価してください。 [議論は噛み合っていましたか？]\"]):\n",
    "    if eval == \"そう思う\":\n",
    "        dict_eval[name].append(4)\n",
    "    elif eval == \"どちらかというとそう思う\":\n",
    "        dict_eval[name].append(3)\n",
    "    elif eval == \"どちらかというとそう思わない\":\n",
    "        dict_eval[name].append(2)\n",
    "    elif eval == \"そう思わない\":\n",
    "        dict_eval[name].append(1)\n",
    "\n",
    "filter_dict_eval = {k: v for k, v in dict_eval.items() if len(v) > 1}\n",
    "\n",
    "std_dict = {}\n",
    "for name, eval in filter_dict_eval.items():\n",
    "    std_dict\n",
    "    std_dict[name] = np.std(eval)\n",
    "\n",
    "print(std_dict)\n",
    "print(\"噛み合い度合い：\"+str(np.mean(list(std_dict.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9230784000933475,\n",
       " 0.03834824944236849,\n",
       " 3.3166247903554,\n",
       " 7,\n",
       " 0.021081851067789197)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.spatial.distance import euclidean, cityblock\n",
    "\n",
    "# Define the two vectors\n",
    "vector_a = np.array([3, 2, 4, 4, 2, 3, 2]) #にわ\n",
    "vector_b = np.array([3, 3, 2, 2, 1, 2, 2]) #ゆーきゃん\n",
    "\n",
    "# 1. Cosine Similarity\n",
    "cosine_similarity = np.dot(vector_a, vector_b) / (np.linalg.norm(vector_a) * np.linalg.norm(vector_b))\n",
    "\n",
    "# 2. Pearson Correlation Coefficient\n",
    "pearson_corr, _ = pearsonr(vector_a, vector_b)\n",
    "\n",
    "# 3. Euclidean Distance\n",
    "euclidean_dist = euclidean(vector_a, vector_b)\n",
    "\n",
    "# 4. Manhattan Distance\n",
    "manhattan_dist = cityblock(vector_a, vector_b)\n",
    "\n",
    "# 5. Spearman's Rank Correlation Coefficient\n",
    "spearman_corr, _ = spearmanr(vector_a, vector_b)\n",
    "\n",
    "cosine_similarity, pearson_corr, euclidean_dist, manhattan_dist, spearman_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.060606060606060774"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# サンプルデータ\n",
    "rater1 = np.array([3, 2, 4, 4, 2, 3, 2])\n",
    "rater2 = np.array([3, 3, 2, 2, 1, 2, 2])\n",
    "\n",
    "# コーエンのカッパ係数の計算\n",
    "kappa = cohen_kappa_score(rater1, rater2)\n",
    "kappa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.11111111111111116"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa\n",
    "\n",
    "# 評価データを定義\n",
    "rater1 = np.array([3, 2, 4, 4, 2, 3, 2])\n",
    "rater2 = np.array([3, 3, 2, 2, 1, 2, 2])\n",
    "\n",
    "# 評価データをカテゴリごとに集計\n",
    "ratings = np.zeros((len(rater1), 4), dtype=int)\n",
    "\n",
    "for i, (r1, r2) in enumerate(zip(rater1, rater2)):\n",
    "    ratings[i, r1 - 1] += 1\n",
    "    ratings[i, r2 - 1] += 1\n",
    "\n",
    "# フリーリーマン・カッパ係数の計算\n",
    "kappa_fleiss = fleiss_kappa(ratings, method='fleiss')\n",
    "kappa_fleiss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
